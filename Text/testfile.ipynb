{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirid\\Downloads\\BobaLoversFinalCapstoneCogworks\\Text\n",
      "File exists: True\n",
      "File size: 3354466 bytes\n",
      "File starts with: b'PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00'\n",
      "Loading GloVe embeddings (this may take a while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sirid\\AppData\\Local\\Temp\\ipykernel_4888\\3882254141.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe 300d embeddings loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import EmbedQ\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "from model1 import EmotionLSTM  # or define EmotionLSTM inline if needed\n",
    "import torch\n",
    "\n",
    "path = r\"C:\\Users\\sirid\\Downloads\\BobaLoversFinalCapstoneCogworks\\best_model.pth\"\n",
    "\n",
    "print(\"File exists:\", os.path.exists(path))\n",
    "print(\"File size:\", os.path.getsize(path), \"bytes\")\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    start = f.read(10)\n",
    "    print(\"File starts with:\", start)\n",
    "\n",
    "model = EmotionLSTM()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "surprise = 'Wait, what?! I didn\\'t see that coming.'\n",
    "disgust = \"That\\'s the grossest-looking pizza I've ever seen.\"\n",
    "fear = \"A chill ran down my spine when I saw the snake.\"\n",
    "anger = \"How could you do this?!\"\n",
    "sadness = \"I feel really lonely\"\n",
    "happiness = \"I\\'m so excited for the trip next week, I\\'m on top of the world right now!\"\n",
    "\n",
    "glove = EmbedQ.load_glove()\n",
    "\n",
    "surprise = EmbedQ.embed_text(surprise, glove)\n",
    "disgust = EmbedQ.embed_text(disgust, glove)\n",
    "fear = EmbedQ.embed_text(fear, glove)\n",
    "anger = EmbedQ.embed_text(anger, glove)\n",
    "sadness = EmbedQ.embed_text(sadness, glove)\n",
    "happiness = EmbedQ.embed_text(happiness, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93105a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ['happiness', 'sadness', 'anger', 'fear', 'surprise', 'disgust']\n",
    "\n",
    "# Wrap each embedding in a list to create a batch with a single sample\n",
    "surprise_batch = [surprise]\n",
    "disgust_batch = [disgust]\n",
    "fear_batch = [fear]\n",
    "anger_batch = [anger]\n",
    "sadness_batch = [sadness]\n",
    "happiness_batch = [happiness]\n",
    "\n",
    "def pad_batch(batch):\n",
    "    padded_sequences = pad_sequence(batch, batch_first=True)\n",
    "    lengths = torch.tensor([seq.size(0) for seq in batch])\n",
    "    return padded_sequences, lengths\n",
    "\n",
    "def get_predictions(dataloader):\n",
    "    outputs_all = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, lengths in dataloader:   # unpack exactly two variables: inputs and lengths\n",
    "            # Debug print (optional):\n",
    "            # print(f\"inputs shape: {inputs.shape}, lengths: {lengths}\")\n",
    "            outputs = model(inputs, lengths)\n",
    "            outputs_all.append(outputs)\n",
    "    return torch.cat(outputs_all, dim=0)\n",
    "\n",
    "surpriseDataloader = DataLoader(surprise_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "disgustDataloader = DataLoader(disgust_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "fearDataloader = DataLoader(fear_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "angerDataloader = DataLoader(anger_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "sadnessDataloader = DataLoader(sadness_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "happinessDataloader = DataLoader(happiness_batch, batch_size=1, shuffle=False, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69c4da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise Predictions: tensor([[ 0.7235,  0.8699,  0.0726,  0.0186,  0.0047, -0.0144]])\n",
      "Disgust Predictions: tensor([[0.5053, 0.6821, 0.0967, 0.0387, 0.0114, 0.0176]])\n",
      "Fear Predictions: tensor([[0.3996, 0.7093, 0.0686, 0.0544, 0.0250, 0.0254]])\n",
      "Anger Predictions: tensor([[ 5.5187e-01,  7.4286e-01,  8.2257e-02,  3.5643e-02,  2.1396e-04,\n",
      "         -1.7214e-02]])\n",
      "Sadness Predictions: tensor([[ 0.6224,  0.7794,  0.0624,  0.0186,  0.0042, -0.0020]])\n",
      "Happiness Predictions: tensor([[0.2332, 0.4918, 0.1107, 0.1216, 0.0115, 0.0297]])\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "surprisePredictions = get_predictions(surpriseDataloader)\n",
    "disgustPredictions = get_predictions(disgustDataloader)\n",
    "fearPredictions = get_predictions(fearDataloader)\n",
    "angerPredictions = get_predictions(angerDataloader)\n",
    "sadnessPredictions = get_predictions(sadnessDataloader)\n",
    "happinessPredictions = get_predictions(happinessDataloader)\n",
    "\n",
    "# Print results\n",
    "print(\"Surprise Predictions:\", surprisePredictions)\n",
    "print(\"Disgust Predictions:\", disgustPredictions)\n",
    "print(\"Fear Predictions:\", fearPredictions)\n",
    "print(\"Anger Predictions:\", angerPredictions)\n",
    "print(\"Sadness Predictions:\", sadnessPredictions)\n",
    "print(\"Happiness Predictions:\", happinessPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputToPred(input_text):\n",
    "\n",
    "    glove = EmbedQ.load_glove()\n",
    "    dummy_label = torch.zeros(6)  \n",
    "    embedded = [(EmbedQ.embed_text(input_text, glove), dummy_label)]\n",
    "    print(embedded[0].shape)\n",
    "    model = model1.EmotionLSTM()\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "    # DataLoader setup  \n",
    "    textDataLoader = DataLoader(embedded, batch_size=1, shuffle=False, collate_fn=pad_batch)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, lengths, _ in textDataLoader:\n",
    "            outputs = model(inputs, lengths)  \n",
    "            pred_vector= outputs.squeeze(0)      \n",
    "\n",
    "    result = {\n",
    "        emotion_labels[i]: round(pred.item(), 3)\n",
    "        for i, pred in enumerate(pred_vector)\n",
    "        if pred.item() > 0\n",
    "    }\n",
    "    return result\n",
    "\n",
    "print(inputToPred(\"I am happy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062bac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Label: surprise\n",
      "Text: Wait, what?! I didn't see that coming.\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.6276\n",
      "  - happiness: 0.6240\n",
      "  - anger: 0.5199\n",
      "  - fear: 0.5051\n",
      "  - surprise: 0.5015\n",
      "  - disgust: 0.4975\n",
      "Weighted Logits: [0.5064367055892944, 0.5219403505325317, 0.07982942461967468, 0.020457318052649498, 0.006166641600430012, -0.010072704404592514]\n",
      "\n",
      "Input Label: disgust\n",
      "Text: That's the grossest-looking pizza I've ever seen.\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.6009\n",
      "  - happiness: 0.5875\n",
      "  - anger: 0.5266\n",
      "  - fear: 0.5106\n",
      "  - surprise: 0.5037\n",
      "  - disgust: 0.5031\n",
      "Weighted Logits: [0.3536751866340637, 0.4092780649662018, 0.10633145272731781, 0.04256168007850647, 0.014793332666158676, 0.012317330576479435]\n",
      "\n",
      "Input Label: fear\n",
      "Text: A chill ran down my spine when I saw the snake.\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.6048\n",
      "  - happiness: 0.5695\n",
      "  - anger: 0.5188\n",
      "  - fear: 0.5150\n",
      "  - surprise: 0.5081\n",
      "  - disgust: 0.5044\n",
      "Weighted Logits: [0.2797470688819885, 0.42556437849998474, 0.07541278004646301, 0.059828583151102066, 0.03254259005188942, 0.017773795872926712]\n",
      "\n",
      "Input Label: anger\n",
      "Text: How could you do this?!\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.6096\n",
      "  - happiness: 0.5954\n",
      "  - anger: 0.5226\n",
      "  - fear: 0.5098\n",
      "  - surprise: 0.5001\n",
      "  - disgust: 0.4970\n",
      "Weighted Logits: [0.38630780577659607, 0.4457181990146637, 0.09048226475715637, 0.039207082241773605, 0.0002781421644613147, -0.012049896642565727]\n",
      "\n",
      "Input Label: sadness\n",
      "Text: I feel really lonely\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.6148\n",
      "  - happiness: 0.6072\n",
      "  - anger: 0.5171\n",
      "  - fear: 0.5051\n",
      "  - surprise: 0.5014\n",
      "  - disgust: 0.4996\n",
      "Weighted Logits: [0.435648113489151, 0.46763208508491516, 0.06860411167144775, 0.020457962527871132, 0.0054105669260025024, -0.0014076981460675597]\n",
      "\n",
      "Input Label: happiness\n",
      "Text: I'm so excited for the trip next week, I'm on top of the world right now!\n",
      "Predicted Emotions:\n",
      "  - sadness: 0.5732\n",
      "  - happiness: 0.5407\n",
      "  - fear: 0.5334\n",
      "  - anger: 0.5304\n",
      "  - disgust: 0.5052\n",
      "  - surprise: 0.5037\n",
      "Weighted Logits: [0.1632441133260727, 0.29507356882095337, 0.12179485708475113, 0.13375405967235565, 0.014986089430749416, 0.02076531946659088]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "\n",
    "# Emotion labels matching the model output order\n",
    "emotion_labels = ['happiness', 'sadness', 'anger', 'fear', 'surprise', 'disgust']\n",
    "\n",
    "# Example class weights â€” adjust these based on your needs:\n",
    "# Lower weight reduces the logit impact (penalizes),\n",
    "# Higher weight increases the logit impact (boosts)\n",
    "class_weights = torch.tensor([\n",
    "    0.7, \n",
    "    0.6,  \n",
    "    1.1, \n",
    "    1.1,  \n",
    "    1.3,  \n",
    "    0.7   \n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Assuming EmbedQ and glove are already loaded and model is initialized\n",
    "# Criterion if needed (not used here since it's inference)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # Embed text into tensor sequence [seq_len, 300]\n",
    "    embedded = EmbedQ.embed_text(text, glove)\n",
    "    return embedded\n",
    "\n",
    "\n",
    "def prepare_batch(tensors):\n",
    "    lengths = torch.tensor([t.size(0) for t in tensors])\n",
    "    padded = pad_sequence(tensors, batch_first=True)  # [batch_size, max_seq_len, 300]\n",
    "    return padded, lengths\n",
    "\n",
    "\n",
    "def predict(texts_dict, model, class_weights):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    # Move weights to same device as model parameters if needed\n",
    "    device = next(model.parameters()).device\n",
    "    weights = class_weights.to(device)\n",
    "\n",
    "    for label, text in texts_dict.items():\n",
    "        embedded = preprocess(text).to(device)\n",
    "        padded, lengths = prepare_batch([embedded])\n",
    "        padded = padded.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(padded, lengths)  # logits shape: [batch_size, num_emotions]\n",
    "            logits = outputs[0]  # for single sample in batch\n",
    "\n",
    "            # Apply element-wise class weights to logits\n",
    "            weighted_logits = logits * weights\n",
    "\n",
    "            # Convert weighted logits to probabilities\n",
    "            scores = torch.sigmoid(weighted_logits)\n",
    "\n",
    "            predicted_emotions = [(emotion_labels[i], scores[i].item()) for i in range(len(emotion_labels))]\n",
    "\n",
    "            results[label] = {\n",
    "                'text': text,\n",
    "                'predicted_emotions': sorted(predicted_emotions, key=lambda x: x[1], reverse=True),\n",
    "                'weighted_logits': weighted_logits.tolist(),\n",
    "                'confidence_scores': scores.tolist()\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Use the predict function\n",
    "results = predict(texts, model, class_weights)\n",
    "\n",
    "# Print formatted results\n",
    "for true_label, data in results.items():\n",
    "    print(f\"\\nInput Label: {true_label}\")\n",
    "    print(f\"Text: {data['text']}\")\n",
    "    print(\"Predicted Emotions:\")\n",
    "    if data['predicted_emotions']:\n",
    "        for emotion, score in data['predicted_emotions']:\n",
    "            print(f\"  - {emotion}: {score:.4f}\")\n",
    "    else:\n",
    "        print(\"  - None above threshold (0.5)\")\n",
    "    print(f\"Weighted Logits: {data['weighted_logits']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
